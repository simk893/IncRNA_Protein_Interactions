{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full database consists of **lncRNA** (long non-enoding RNA) x **RBP** (RNA-Binding Protein) predicted binding interactions at each 101 nucleotide sequence along the lncRNAs resuling in an **36,000** dataframes of size **154** x **N<sub>i</sub>**, where **N<sub>i</sub>** represents the # of unique nucleotide segments in **lncRNA<sub>i</sub>** for **i = 1, ..., 36,000**.\n",
    "\n",
    "Below is an example of the dataframe and and the predicted binding probabilites for **RBPs** (*AATF*, *ABCF1*, *AUH*, *BCCIP*,*BCLAF1*) along **lncRNA<sub>13</sub>** (*ENST00000366136.2*) with **N<sub>13</sub>** = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\simeo\\OneDrive\\Documents\\UNC\\Spring 2025\\STOR 765\\lncRNA_x_RBP_Data\\chr1\\ENST00000366136.2_predictions.tsv\"\n",
    "df = pd.read_csv(path, sep='\\t')\n",
    "Index = 5\n",
    "sample_proteins = df.columns[Index+2:Index+6]\n",
    "display(df.loc[:, ['rna_index', 'dna_index'] + list(sample_proteins)].head())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for rbp in sample_proteins:\n",
    "    plt.plot(range(len(df)), df[rbp], marker='o', linestyle='--', label=rbp)\n",
    "plt.title('Predicted lncRNA x RBP Binding Probabilities')\n",
    "plt.xlabel('101 RNA Nuceotide Sequence Index')\n",
    "plt.ylabel('Binding Probability')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a series of subplots to visualize the binding probabilities of RNA-binding proteins (RBPs) and their statistical properties within percentile bins. Each subplot shows the following:\n",
    "\n",
    "1. **Binding Probabilities**: The binding probabilities of the RBP across the RNA sequence are plotted as a black dashed line with markers.\n",
    "2. **Mean and Median Index Values**: The mean and median index values for each percentile bin are plotted as red scatter points.\n",
    "3. **Error Bars**: Horizontal dashed lines represent the standard deviation around the mean index values.\n",
    "4. **Bin Edges**: Horizontal dashed lines indicate the edges of the percentile bins.\n",
    "\n",
    "The subplots provide a detailed view of the distribution and variability of binding probabilities for the first four RBPs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "for ax, rbp in zip(axes.flatten(), sample_proteins):\n",
    "    N = 5\n",
    "    bps = df[rbp].values\n",
    "    bins = np.linspace(0, 1, N + 1)\n",
    "    bin_indices = np.digitize(bps, bins) - 1\n",
    "    average_index_values = []\n",
    "    variance_index_values = []\n",
    "    median_index_values = []\n",
    "    for i in range(N):\n",
    "        indices_in_bin = np.where(bin_indices == i)[0]\n",
    "        if len(indices_in_bin) > 0:\n",
    "            average_index_values.append(indices_in_bin.mean())\n",
    "            variance_index_values.append(indices_in_bin.var())\n",
    "            median_index_values.append(np.median(indices_in_bin))\n",
    "        else:\n",
    "            average_index_values.append(np.nan)\n",
    "            variance_index_values.append(np.nan)\n",
    "            median_index_values.append(np.nan)\n",
    "    y_coordinates = [(bins[i] + bins[i + 1]) / 2 for i in range(N)]\n",
    "    ax.plot(range(len(df)), df[rbp], marker='o', linestyle='--', color='black', label=rbp + ' Binding Probabilities')\n",
    "    ax.scatter(average_index_values, y_coordinates, color='red', label='Mean Index Value per Percentile Bin')\n",
    "    ax.scatter(median_index_values, y_coordinates, color='red', marker='*', s=100, label='Median Index Value per Percentile Bin')\n",
    "    for i in range(N):\n",
    "        if not np.isnan(average_index_values[i]):\n",
    "            lower_bound = average_index_values[i] - np.sqrt(variance_index_values[i])\n",
    "            upper_bound = average_index_values[i] + np.sqrt(variance_index_values[i])\n",
    "            ax.hlines(y_coordinates[i], lower_bound, upper_bound, colors='red', linestyles='dashed', alpha=0.5)\n",
    "            ax.plot([lower_bound, lower_bound], [y_coordinates[i] - 0.01, y_coordinates[i] + 0.01], color='red')\n",
    "            ax.plot([upper_bound, upper_bound], [y_coordinates[i] - 0.01, y_coordinates[i] + 0.01], color='red')\n",
    "    for y in bins[1:-1]:\n",
    "        ax.axhline(y, color='black', linestyle='--', alpha=0.5)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(f'Mean, Median, and Std Dev of {rbp} in Each Percentile Bin')\n",
    "    ax.set_xlabel('101 RNA Nucleotide Sequence Index')\n",
    "    ax.set_ylabel('Binding Probability')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a series of subplots to visualize various statistical properties of RNA-binding proteins (RBPs) within percentile bins. Each subplot shows the following:\n",
    "\n",
    "1. **Proportion of Binding Probabilities**: The proportion of binding probabilities in each percentile bin.\n",
    "2. **Mean Index of Binding Probabilities**: The mean index values of binding probabilities in each percentile bin.\n",
    "3. **Variance of Index of Binding Probabilities**: The variance of index values of binding probabilities in each percentile bin.\n",
    "4. **Skewness of Index of Binding Probabilities**: The skewness of index values of binding probabilities in each percentile bin.\n",
    "\n",
    "The subplots provide a detailed view of the distribution and variability of binding probabilities for the first four RBPs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {'Proportion': {}, 'Mean': {},'Variance': {},'Skew': {}}\n",
    "N = 5\n",
    "indices = np.arange(50, 50 + 10 * len(df), 10)\n",
    "normalized_indices = indices / indices.max()\n",
    "for rbp in sample_proteins:\n",
    "    bps = df[rbp].values\n",
    "    bins = np.linspace(0, 1, N + 1)\n",
    "    bin_indices = np.digitize(bps, bins) - 1\n",
    "    proportion_values, mean_index_values, variance_index_values, skew_index_values = [], [], [], []\n",
    "    for i in range(N):\n",
    "        indices_in_bin = np.where(bin_indices == i)[0]\n",
    "        if len(indices_in_bin) > 0:\n",
    "            mean_index_values.append(normalized_indices[indices_in_bin].mean())\n",
    "            variance_index_values.append(normalized_indices[indices_in_bin].var())\n",
    "            proportion_values.append(len(indices_in_bin) / len(indices))\n",
    "            skew_index_values.append(skew(normalized_indices[indices_in_bin]))\n",
    "        else:\n",
    "            mean_index_values.append(np.nan)\n",
    "            variance_index_values.append(np.nan)\n",
    "            proportion_values.append(np.nan)\n",
    "            skew_index_values.append(np.nan)\n",
    "    var_dict['Proportion'][rbp], var_dict['Mean'][rbp] = proportion_values, mean_index_values\n",
    "    var_dict['Variance'][rbp], var_dict['Skew'][rbp] = skew_index_values = variance_index_values, skew_index_values\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "for ax, (key, title, ylabel) in zip(axes.flatten(), \n",
    "                                    [('Proportion', 'Proportion of Binding Probabilities in Each Percentile Bin', 'Proportion of RBP Binding Probabilities'),\n",
    "                                     ('Mean', 'Mean Index of Binding Probabilities in Each Percentile Bin', 'Mean Index of RBP Binding Probabilities'),\n",
    "                                     ('Variance', 'Variance of Index of Binding Probabilities in Each Percentile Bin', 'Variance of Index of RBP Binding Probabilities'),\n",
    "                                     ('Skew', 'Skewness of Index of Binding Probabilities in Each Percentile Bin', 'Skewness of Index of RBP Binding Probabilities')]):\n",
    "    for rbp in var_dict[key]:\n",
    "        ax.plot(range(N), var_dict[key][rbp], marker='o', linestyle='--', label=rbp)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Percentile Bins')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(range(N))\n",
    "    ax.set_xticklabels([f'{i/N:.1f}-{(i+1)/N:.1f}' for i in range(N)], rotation=45)\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a series of subplots to visualize the binding probabilities of RNA-binding proteins (RBPs) and their Fourier Transform reconstructions. Each subplot shows the following:\n",
    "\n",
    "1. **Original Binding Probabilities**: The original binding probabilities of the RBP across the RNA sequence are plotted as a semi-transparent line.\n",
    "2. **Fourier Reconstruction**: The reconstructed signal using the top K Fourier components is plotted as dashed lines for different values of K (3, 7, and 12).\n",
    "\n",
    "The subplots provide a comparison between the original binding probabilities and their Fourier Transform reconstructions, highlighting how well the top K Fourier components capture the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "for ax, rbp in zip(axes.flatten(), df.columns[2+5:6+5]):\n",
    "    bps = df[rbp].values\n",
    "    n = len(bps)\n",
    "    K = [5, 10, 15]\n",
    "    bps_fft = np.fft.fft(bps)\n",
    "    freqs = np.fft.fftfreq(n, d=1)\n",
    "    magnitudes = np.abs(bps_fft) / n\n",
    "    indices_sorted = np.argsort(magnitudes)[::-1]\n",
    "    \n",
    "    # Plot the original data with increased linewidth and alpha\n",
    "    ax.plot(np.arange(n), bps, label=rbp, color='black', linewidth=2.5, alpha=0.8)\n",
    "    \n",
    "    for k in K:\n",
    "        top_indices = indices_sorted[:k]\n",
    "        filtered_fft = np.zeros_like(bps_fft, dtype=complex)\n",
    "        filtered_fft[top_indices] = bps_fft[top_indices]\n",
    "        filtered_fft[-top_indices] = bps_fft[-top_indices]\n",
    "        y_reconstructed = np.fft.ifft(filtered_fft).real\n",
    "        \n",
    "        # Plot the reconstructed data with alpha\n",
    "        ax.plot(np.arange(n), y_reconstructed, label=f'{k} Waves', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    ax.set_title(f\"lncRNA x RBP data vs. Fourier Reconstruction ({rbp})\")\n",
    "    ax.set_xlabel('101 RNA Nucleotide Sequence Index')\n",
    "    ax.set_ylabel('Predicted Binding Probability')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert correlation explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_columns = df.columns[2:]\n",
    "correlation_matrix = df[protein_columns].corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm', fmt='.2f', cbar_kws={\"shrink\": .8},\n",
    "            xticklabels=protein_columns, yticklabels=protein_columns)\n",
    "plt.title('RBP x RBP Correlation Matrix')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process_file` function processes a given file containing lncRNA x RBP predicted binding interactions and extracts various features. Here is a summary of its steps:\n",
    "\n",
    "1. **Read Data**: Reads the input file into a DataFrame.\n",
    "2. **Initialize Variables**: Sets up variables for the number of bins (`N`), top Fourier frequencies (`K`), and autocorrelation lags (`L`).\n",
    "3. **Percentile-based Summary Statistics**:\n",
    "    - Bins the binding probabilities for each protein into `N` bins = [0 , 1/N] , ... , [N-1/N , 1].\n",
    "    - Calculates the proportion, mean, variance, and skew forming the distribution of binding probabilites within each bin.\n",
    "    - Stores the binned summary statistics in a dictionary.\n",
    "4. **Top K Fourier Frequencies and Magnitudes**:\n",
    "    - Computes the Fourier transform of the signal for each protein.\n",
    "    - Extracts the top `K` more relevant frequencies and their respective magnitudes.\n",
    "    - Stores these values in the dictionary.\n",
    "5. **Correlation Matrix**:\n",
    "    - Computes the correlation of binding probabilties between each pair of proteins.\n",
    "    - Stores these values in the dictionary.\n",
    "6. **Convert to DataFrame**: Converts the dictionary of features into a single-row DataFrame and returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computationally Optimized Feature Extraction\n",
    "# ---------------------------------------------\n",
    "# 1. Define your feature_extraction function\n",
    "# ---------------------------------------------\n",
    "def feature_extraction(df, N=0, K=0, lags=True):\n",
    "    \"\"\"\n",
    "    Extract features for a single DataFrame `df`. \n",
    "    Returns a 1-row DataFrame containing the computed features.\n",
    "\n",
    "    df: DataFrame with at least 3 columns (df.columns[2:] used for RBP variables).\n",
    "    N : number of bins for binning-based stats\n",
    "    K : number of top FFT frequencies\n",
    "    L : maximum lag for autocorrelation\n",
    "    lags: boolean to determine if lag calculations should be performed\n",
    "    \"\"\"\n",
    "    # Identify columns to process\n",
    "    RBPs = df.columns[2:]  # adjust as needed\n",
    "    M = len(RBPs)          # number of RBP columns\n",
    "\n",
    "    # Convert RBP columns to NumPy array for faster access\n",
    "    data_array = df[RBPs].values\n",
    "    n_points = len(df)\n",
    "\n",
    "    # Dictionary to hold final feature values\n",
    "    feature_dict = {}\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # (A) Bin-based statistics: proportion, mean, variance, skew\n",
    "    # -----------------------------------------\n",
    "    bins = np.linspace(0, 1, N+1)\n",
    "    indices = np.arange(50, 50 + 10*n_points, 10)\n",
    "    normalized_indices = indices / indices.max()\n",
    "\n",
    "    for col_idx, rbp in enumerate(RBPs):\n",
    "        bps = data_array[:, col_idx]\n",
    "\n",
    "        # Digitize bps into bins [0..N-1]\n",
    "        bin_indices = np.digitize(bps, bins) - 1\n",
    "\n",
    "        # Group once to avoid repeated np.where\n",
    "        grouped_indices = [[] for _ in range(N)]\n",
    "        for i, bin_idx in enumerate(bin_indices):\n",
    "            if 0 <= bin_idx < N:\n",
    "                grouped_indices[bin_idx].append(i)\n",
    "\n",
    "        # Compute stats for each bin\n",
    "        for i in range(N):\n",
    "            idxs = grouped_indices[i]\n",
    "            prefix = f\"{rbp}_percentile_bin_{i}\"\n",
    "\n",
    "            if len(idxs) > 0:\n",
    "                bin_norm = normalized_indices[idxs]\n",
    "                feature_dict[f\"{prefix}_proportion\"] = len(idxs) / n_points\n",
    "                feature_dict[f\"{prefix}_mean\"]       = bin_norm.mean()\n",
    "                feature_dict[f\"{prefix}_variance\"]   = bin_norm.var()\n",
    "                feature_dict[f\"{prefix}_skew\"]       = skew(bin_norm)\n",
    "            else:\n",
    "                feature_dict[f\"{prefix}_proportion\"] = np.nan\n",
    "                feature_dict[f\"{prefix}_mean\"]       = np.nan\n",
    "                feature_dict[f\"{prefix}_variance\"]   = np.nan\n",
    "                feature_dict[f\"{prefix}_skew\"]       = np.nan\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # (B) Top K FFT frequencies\n",
    "    # -----------------------------------------\n",
    "    if K > 0:\n",
    "        for col_idx, rbp in enumerate(RBPs):\n",
    "            bps = data_array[:, col_idx]\n",
    "            n_i = len(bps)\n",
    "\n",
    "            bps_fft = np.fft.fft(bps)\n",
    "            freqs   = np.fft.fftfreq(n_i, d=1.0)\n",
    "            mags    = np.abs(bps_fft) / n_i\n",
    "\n",
    "            # Find indices of top K using argpartition (O(n)) if K < n_i\n",
    "            if K < n_i:\n",
    "                top_k_idx = np.argpartition(mags, -K)[-K:]\n",
    "                top_k_idx = top_k_idx[np.argsort(mags[top_k_idx])[::-1]]\n",
    "            else:\n",
    "                top_k_idx = np.argsort(mags)[::-1]\n",
    "\n",
    "            for rank, idx in enumerate(top_k_idx, start=1):\n",
    "                feature_dict[f\"{rbp}_Frequency_{rank}\"] = freqs[idx]\n",
    "                feature_dict[f\"{rbp}_Magnitude_{rank}\"] = mags[idx]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # (C) Correlation Calculations\n",
    "    # -----------------------------------------\n",
    "    if lags:\n",
    "        # Vectorized correlation among columns\n",
    "        corr_matrix = pd.DataFrame(data_array, columns=RBPs).corr()\n",
    "        for i in range(M):\n",
    "            for j in range(i+1, M):\n",
    "                rbp1, rbp2 = RBPs[i], RBPs[j]\n",
    "                feature_dict[f\"{rbp1}_x_{rbp2}\"] = corr_matrix.iloc[i, j]\n",
    "\n",
    "    # Return single-row DataFrame\n",
    "    return pd.DataFrame([feature_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_with_progress(file_paths, N=0, K=0, lags=True):\n",
    "    \"\"\"\n",
    "    Serially process multiple files, showing a tqdm progress bar.\n",
    "    Returns a DataFrame with one row per file.\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    combined_df = []\n",
    "    row_names = []\n",
    "    error_files = []\n",
    "    processed_files = 0\n",
    "\n",
    "    with tqdm(file_paths, desc=\"Extracting Features\", unit=\"lncRNA\") as pbar:\n",
    "        for path in pbar:\n",
    "            try:\n",
    "                # Read data once\n",
    "                df = pd.read_csv(path, sep='\\t')\n",
    "                \n",
    "                # Extract features\n",
    "                result_df = feature_extraction(df, N=N, K=K, lags=lags)\n",
    "                \n",
    "                # Accumulate results\n",
    "                combined_df.append(result_df)\n",
    "                \n",
    "                # Optionally, create a meaningful row name from filename\n",
    "                row_names.append(os.path.basename(path).replace(\"_predictions.tsv\", \"\"))\n",
    "\n",
    "                processed_files += 1\n",
    "            except Exception as e:\n",
    "                error_files.append(path)\n",
    "                continue\n",
    "\n",
    "    # Concatenate all single-row DataFrames\n",
    "    final_df = pd.concat(combined_df).set_index(pd.Index(row_names))\n",
    "    return final_df, error_files, processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, K, lags = 10, 25, True\n",
    "directory_path = r\"C:\\Users\\simeo\\OneDrive\\Documents\\UNC\\Spring 2025\\STOR 765\\lncRNA_x_RBP_Data\"\n",
    "\n",
    "# Initialize variables\n",
    "errors = []\n",
    "processed_files = 0\n",
    "\n",
    "# Get the list of files\n",
    "files = [os.path.join(folder_path, filename)\n",
    "         for folder in os.listdir(directory_path)\n",
    "         if os.path.isdir(folder_path := os.path.join(directory_path, folder))\n",
    "         for filename in os.listdir(folder_path)\n",
    "         if filename.endswith(\".tsv\")]\n",
    "\n",
    "# Process files in smaller chunks to avoid memory issues\n",
    "chunk_size = 1000  # Number of files to process at a time\n",
    "all_features_df_list = []\n",
    "\n",
    "output_csv_path = os.path.join(r\"C:\\Users\\simeo\\Documents\", f\"final_features_N{N}_K{K}{\"_Corr\" if lags else \"\"}.csv\")\n",
    "print(f\"Processing {len(files)} files in chunks of {chunk_size}...\")\n",
    "\n",
    "# Process all files in one go\n",
    "all_features_df, errors, processed_files = process_files_with_progress(files, N=N, K=K, lags=lags)\n",
    "\n",
    "# Save the entire DataFrame to the CSV file\n",
    "all_features_df.to_csv(output_csv_path, mode='w')\n",
    "\n",
    "print(f\"Processed {processed_files} files. Errors encountered in {len(errors)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCS = 4  # Specify the number of principal components to include\n",
    "pca_components_df = pd.DataFrame(pca.components_, columns=all_features_df.columns)\n",
    "pca_components_df.index = [f\"PC{i+1}\" for i in range(len(pca_components_df))]\n",
    "\n",
    "# Extract unique protein names from column names\n",
    "proteins = list({col.split('_')[0] for col in pca_components_df.columns})\n",
    "\n",
    "# Combine the results into a DataFrame\n",
    "combined_results = []\n",
    "\n",
    "for protein in proteins:\n",
    "    # Filter columns associated with the current protein\n",
    "    protein_columns = [col for col in pca_components_df.columns if col.startswith(protein)]\n",
    "    protein_frequency_columns = [col for col in protein_columns if 'Frequency' in col]\n",
    "    protein_magnitude_columns = [col for col in protein_columns if 'Magnitude' in col]\n",
    "\n",
    "    # Extract loadings for the first K PCs for frequency and magnitude variables\n",
    "    for pc in range(1, PCS + 1):\n",
    "        pc_label = f\"PC{pc}\"\n",
    "        protein_pc_frequency_loadings = pca_components_df.loc[pc_label, protein_frequency_columns]\n",
    "        protein_pc_magnitude_loadings = pca_components_df.loc[pc_label, protein_magnitude_columns]\n",
    "\n",
    "        # Combine frequency and magnitude loadings into a DataFrame\n",
    "        protein_combined_data = pd.DataFrame({\n",
    "            'Feature': protein_frequency_columns + protein_magnitude_columns,\n",
    "            'Loading Value': list(protein_pc_frequency_loadings) + list(protein_pc_magnitude_loadings),\n",
    "            'Type': ['Frequency'] * len(protein_frequency_columns) + ['Magnitude'] * len(protein_magnitude_columns),\n",
    "            'Protein': protein,\n",
    "            'Principal Component': pc_label\n",
    "        })\n",
    "        combined_results.append(protein_combined_data)\n",
    "\n",
    "# Concatenate all protein data into a single DataFrame\n",
    "final_combined_df = pd.concat(combined_results, ignore_index=True)\n",
    "final_combined_df\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Prepare the data for the 3D scatter plot\n",
    "final_combined_df['Category'] = final_combined_df['Type']  # Add a category column for better visualization\n",
    "final_combined_df['Index'] = final_combined_df['Feature'].str.extract(r'_(\\d+)$').astype(int)  # Extract index from feature names\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare the data for the 3D scatter plot\n",
    "final_combined_df['Category'] = final_combined_df['Type']  # Add a category column for better visualization\n",
    "final_combined_df['Index'] = final_combined_df['Feature'].str.extract(r'_(\\d+)$').astype(int)  # Extract index from feature names\n",
    "\n",
    "# Create a 2x2 subplot figure\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}],\n",
    "           [{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "    subplot_titles=[f\"3D Line Plot of {pc}\" for pc in final_combined_df['Principal Component'].unique()]\n",
    ")\n",
    "\n",
    "# Iterate over each principal component and add a 3D line plot to the subplot\n",
    "unique_pcs = final_combined_df['Principal Component'].unique()\n",
    "for i, pc in enumerate(unique_pcs):\n",
    "    pc_data = final_combined_df[final_combined_df['Principal Component'] == pc]\n",
    "\n",
    "    # Separate data for frequency and magnitude\n",
    "    frequency_data = pc_data[pc_data['Type'] == 'Frequency']\n",
    "    magnitude_data = pc_data[pc_data['Type'] == 'Magnitude']\n",
    "\n",
    "    # Iterate over each protein to create separate line groups\n",
    "    for protein in proteins:\n",
    "        protein_frequency_data = frequency_data[frequency_data['Protein'] == protein]\n",
    "        protein_magnitude_data = magnitude_data[magnitude_data['Protein'] == protein]\n",
    "\n",
    "        # Create the 3D line plot for frequency\n",
    "        frequency_scatter3d = go.Scatter3d(\n",
    "            x=protein_frequency_data['Protein'],\n",
    "            y=protein_frequency_data['Index'],\n",
    "            z=protein_frequency_data['Loading Value'],\n",
    "            mode='lines+markers',\n",
    "            line=dict(width=2, color='blue'),\n",
    "            marker=dict(size=2),\n",
    "            name=f\"{pc} - Frequency - {protein}\",\n",
    "            legendgroup=f\"{pc} - Frequency - {protein}\",\n",
    "            text=protein_frequency_data['Category'],\n",
    "            hoverinfo='text+x+y+z'\n",
    "        )\n",
    "\n",
    "        # Create the 3D line plot for magnitude\n",
    "        magnitude_scatter3d = go.Scatter3d(\n",
    "            x=protein_magnitude_data['Protein'],\n",
    "            y=protein_magnitude_data['Index'],\n",
    "            z=protein_magnitude_data['Loading Value'],\n",
    "            mode='lines+markers',\n",
    "            line=dict(width=2, color='red'),\n",
    "            marker=dict(size=2),\n",
    "            name=f\"{pc} - Magnitude - {protein}\",\n",
    "            legendgroup=f\"{pc} - Magnitude - {protein}\",\n",
    "            text=protein_magnitude_data['Category'],\n",
    "            hoverinfo='text+x+y+z'\n",
    "        )\n",
    "\n",
    "        # Determine the row and column for the subplot\n",
    "        row = i // 2 + 1\n",
    "        col = i % 2 + 1\n",
    "\n",
    "        # Add the traces to the subplot\n",
    "        fig.add_trace(frequency_scatter3d, row=row, col=col)\n",
    "        fig.add_trace(magnitude_scatter3d, row=row, col=col)\n",
    "\n",
    "    # Update the layout for the subplot\n",
    "    fig.update_scenes(\n",
    "        dict(\n",
    "            xaxis=dict(\n",
    "                title='Proteins',\n",
    "                tickvals=list(range(len(proteins))),\n",
    "                ticktext=proteins,\n",
    "                tickfont=dict(size=10),  # Make tick text smaller\n",
    "                tickmode='array',\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Fourier Waves',\n",
    "                tickvals=list(range(1, 51)),\n",
    "                ticktext=list(range(1, 51)),\n",
    "                tickfont=dict(size=10),  # Make tick text smaller\n",
    "                tickmode='array',\n",
    "            ),\n",
    "            zaxis_title='Loadings'\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "\n",
    "# Update the overall layout\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=1000,\n",
    "    title=\"3D Line Plots for Principal Components\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
